{"componentChunkName":"component---src-templates-page-template-js","path":"/buildingACloudMigrationPlatformPart1ProvisioningTheInfrastructure","result":{"pageContext":{"page":{"author":"Arun Madhavan","content":"<h1>Building A Cloud Migration Platform - Part 1 : Provisioning the infrastructure</h1>\n<p>A recent change in our Org, all the applications are required to be moved to GCP as part of a strategic decision.\nMost of our apps run out of Azure today with a few services deployed in AWS as well, with tons of other apps running out of on-prem datacenters. </p>\n<p>There has been lots of work done by different people across different teams to migrate their apps into GCP. Though there is generally good sharing of information,\nthe loss of information exchange is also quite common due to the shear size of the organization. Another major problem is lack of working knowledge in GCP, which is an org wide issue.\nNot every one is aware of the best practices that needs to be followed as part of their provisioning of infrastructure, which components to choose etc. and there still exists a lot of learning curve to go through. </p>\n<p>Recently as part of the GCP adoption initiative, we had a hackathon conducted and we pitted in with a solution to make things simple for teams to move to GCP. This solution takes inspiration from one of the best products that I have worked on developing a few years back, which helped me architect this solution. </p>\n<p>I'll share my thoughts on how we approached the problem statement as part of this blog series. As part of this blog, we will see how we approached the problem of provisioning the infrastructure components in GCP. </p>\n<h2>TLDR;</h2>\n<p>We built a stateless microservice - \"Step Executor\", that takes in request to trigger a Terraform script and respond back with the step output.\nA GCP component provisioning might need provisioning of other components as pre-requisites. These we modelled it as a Plan with multiple steps.\nEach step is a terraform script, and a plan consists of multiple smaller steps.\nThe execution of a plan and it's many smaller steps is handled by another microservice called the \"Orchestrator\" that executes the steps in sequence.</p>\n<h2>Overall Application</h2>\n<p>We planned to build a platform that would be able to </p>\n<ul>\n<li>Understand the application that needs migration</li>\n<li>Identify the current components used and the infrastructure in which they are deployed ( Azure/ AWS/ On-Prem )</li>\n<li>Suggest GCP specific alternatives, and come up with a migration plan</li>\n<li>Auto provision the components identifed</li>\n<li>Provide a platform that can also act as a source for all the application information ( like a keyvaule ) </li>\n</ul>\n<p>So the flow can be broadly represented as </p>\n<p><img src=\"./images/migrationPlatform/OverallFlow.svg\" alt=\"Overall Flow\"></p>\n<p>Our overall architecture had the below components </p>\n<p><img src=\"./images/migrationPlatform/overall-architecture.svg\" alt=\"Overall Architecture\"></p>\n<table>\n<thead>\n<tr>\n<th>Service/ Component</th>\n<th>Description</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>UI</td>\n<td>A react based UI application, that was used for user interactions</td>\n</tr>\n<tr>\n<td>Mediator</td>\n<td>A spring boot application, which acts as the backend for the UI, and is responsible for identifying the components from the user and works with other services to identify and provision the components.</td>\n</tr>\n<tr>\n<td>Suggestion Engine</td>\n<td>An engine that takes the current application information to suggest a migration plan. Built as a spring boot application this integrated with many other services for analysis and prediction</td>\n</tr>\n<tr>\n<td>Orchestrator</td>\n<td>A spring boot service, that takes a migration plan, and orchestrates the creation of components in GCP</td>\n</tr>\n<tr>\n<td>Step Executor</td>\n<td>The Node and Typescript application that triggers terraform scripts for the actual provisioning of components, based on the inputs passed from Orchestrator</td>\n</tr>\n</tbody>\n</table>\n<p>In this blog post, we'll specifically how we designed and developed the Step Executor. </p>\n<h2>Provisioning of GCP Components</h2>\n<p>We decided that to automate the provisioning process, it is essential that we codify the process. We had options to choose from and the major 2 options that we wanted to leverage were <strong>Terraform</strong> and <strong>Google Cloud Deployment Manager</strong>. We decided to go with terraform as it would provide a way to make the solution platform agnostic. So in case of a shift in company strategy in future to choose a different cloud service, the platform would require re-work only on the Terraform scripts, with the rest of the services being intact. </p>\n<p>Typically a component provsioning might also need provisioning of related components, before the actual component is provisioned. For example, if one of the requirement is to create a Postgres DB in GCP's Cloud SQL, it would require creation of VPC and Subnet inside which the DB needs to be provisioned to provide it with required level of network isolation and security.  So this would mean that for spinning up a DB I need to </p>\n<ol>\n<li>Provision a VPC </li>\n<li>Provision a Subnet inside the VPN</li>\n<li>Pass the subnet information while Spinning up the DB</li>\n</ol>\n<p>We call this an execution plan or to put it simply <strong>Plan</strong>. A plan consists of many individual steps. In the case above, the plan has 3 steps, viz. Provisiong of  VPC, Subnet and DB. A step can have inputs that are passed from the user, or from one of it's previous steps. </p>\n<p>For Example, a database provisioning needs the Size and Name of the DB, that would come from the user, whereas the subnet under which it needs to get created would come from it's previous step. </p>\n<p>Addition to the inputs from the user provisioning of infrastructure also needs security. Each team needs to isloate their components from the others and they will behave like an org of their own. So each team will have to pass their own security for provisioning their components. </p>\n<p>So in short, during each step's execution, terraform would take the user/step inputs and security details to execute the script and provision a single component.</p>\n<p>With the above information in hand, let's take a look into how we were able to pull off an actual implementation. </p>\n<h2>Step Executor</h2>\n<p>Step Executor was a service that exposed a single POST endpoint, to which we can pass a set of input and security information, based on which it would choose and run a terraform script. The endpoint would handle the request in an async fashion and will make a call back to a webhook endpoint exposed at the \"Orchestrator Service\" ( to be discussed later ) with the output from terraform. </p>\n<h3>Terraform Rules</h3>\n<p>To ensure uniformity across all the different scripts we wanted to set the following rules for terraform scripts</p>\n<ol>\n<li>Every script is used to create a single component</li>\n<li>Every script takes a set of input and exposes a set of output </li>\n<li>All the terraform scripts would read credentials from a credentials file called <code>auth.json</code></li>\n<li>The inputs are directly passed to the <code>terraform plan</code> or <code>terraform apply</code> commands</li>\n<li>The output of the <code>terraform apply</code> command is written into <code>terraform.tfstate</code> state file </li>\n</ol>\n<p>Below is a sample terraform file that we used for creating a postgres DB in Cloud SQL along with an admin user</p>\n<pre><code>provider \"google\" {\n    credentials = file(var.credentials_file)\n    project = var.project\n}\n\nprovider \"google-beta\" {\n    credentials = file(var.credentials_file)\n    project = var.project\n}\n\nvariable \"project\" { \n    default = \"\"\n}\n\nvariable \"credentials_file\" {\n    default = \"auth.json\"\n}\n\nvariable \"region\" {\n  default = \"us-central1\"\n}\n\nvariable \"zone\" {\n  default = \"us-central1-c\"\n}\n\n# database instance settings\nvariable db_version {\n  default = \"POSTGRES_11\"\n}\n\nvariable db_tier {\n  default = \"db-f1-micro\"\n}\n\nvariable db_activation_policy {\n  default = \"ALWAYS\"\n}\n\nvariable db_disk_autoresize {\n  default = true\n}\n\nvariable db_disk_size {\n  default = 10\n}\n\nvariable db_disk_type {\n  default = \"PD_SSD\"\n}\n\nvariable db_pricing_plan {\n  default = \"PER_USE\"\n}\n\nvariable db_instance_access_cidr {\n  default = \"0.0.0.0/0\"\n}\n\n# database settings\nvariable db_name {\n  description = \"Name of the default database to create\"\n  default = \"default_db\"\n}\n\nvariable db_charset {\n  description = \"The charset for the default database\"\n  default = \"\"\n}\n\nvariable db_collation {\n  description = \"The collation for the default database. Example for MySQL databases: 'utf8_general_ci'\"\n  default = \"\"\n}\n\n# user settings\nvariable db_user_name {\n  description = \"The name of the default user\"\n  default = \"admin\"\n}\n\nvariable db_user_host {\n  description = \"The host for the default user\"\n  default = \"%\"\n}\n\nvariable db_user_password {\n  default = \"\"\n}\n\noutput \"connection_name\" {\n  value       = google_sql_database_instance.postgresql.*.connection_name\n  description = \"Postgress Connection Name\"\n}\n\nresource \"google_sql_database_instance\" \"postgresql\" {\n  \n  provider = google\n\n  name = \"postgresql\"\n  project = var.project\n  region = var.region\n  database_version = \"${var.db_version}\"\n  \n  settings {\n    tier = \"${var.db_tier}\"\n    activation_policy = \"${var.db_activation_policy}\"\n    disk_autoresize = \"${var.db_disk_autoresize}\"\n    disk_size = \"${var.db_disk_size}\"\n    disk_type = \"${var.db_disk_type}\"\n    pricing_plan = \"${var.db_pricing_plan}\"\n    \n    location_preference {\n      zone = var.zone\n    }\n   \n    ip_configuration {\n      ipv4_enabled = \"true\"\n      authorized_networks {\n        value = \"${var.db_instance_access_cidr}\"\n      }\n    }\n  }\n}\n\n# create database\nresource \"google_sql_database\" \"postgresql_db\" {\n  provider = google-beta\n\n  name = \"${var.db_name}\"\n  project = \"${var.project}\"\n  instance = \"${google_sql_database_instance.postgresql.name}\"\n  charset = \"${var.db_charset}\"\n  collation = \"${var.db_collation}\"\n}\n\n# create user\nresource \"random_id\" \"user_password\" {\n  byte_length = 8\n}\n\nresource \"google_sql_user\" \"postgresql_user\" {\n\n  provider = google-beta\n\n  name = \"${var.db_user_name}\"\n  project  = \"${var.project}\"\n  instance = \"${google_sql_database_instance.postgresql.name}\"\n  host = \"${var.db_user_host}\"\n  password = \"${var.db_user_password == \"\" ?\n  random_id.user_password.hex : var.db_user_password}\"\n}\n</code></pre>\n<p>The final execution consisted of </p>\n<ul>\n<li>Creating a <code>temp</code> Folder</li>\n<li>Moving the terraform file tat needs to be executed</li>\n<li>Creating an <code>auth.json</code> based on the security information passed</li>\n<li>Executing <code>terraform init</code> to iniaitlize all the plugins required for executing the script</li>\n<li>Executing <code>terraform plan -vars...</code> for creating the execution plan</li>\n<li>Executing <code>terraform apply -vars...</code> to actually provision the resources</li>\n</ul>\n<h3>Implementation</h3>\n<p>With the above steps defined, we did an implementation using NodeJs and Typescript, exposing a POST endpoint. It took the following input as request body</p>\n<pre><code>{\n    \"traceId\": \"traceID from the requesting system\", \n    \"stepName\": \"name of the terraform that needs to be executed\", \n    \"auth\": { \"type\": \"service_account\",\n      \"project_id\": \"&#x3C;project id from GCP>\",\n      \"private_key_id\": \"&#x3C;keyId>\",\n      \"private_key\": \"&#x3C;Private Key>\",\n      \"client_email\": \"&#x3C;service email>\",\n      \"client_id\": \"&#x3C;GCP Client Id>\",\n      \"auth_uri\": \"https://accounts.google.com/o/oauth2/auth\",\n      \"token_uri\": \"https://oauth2.googleapis.com/token\",\n      \"auth_provider_x509_cert_url\": \"https://www.googleapis.com/oauth2/v1/certs\",\n      \"client_x509_cert_url\": \"&#x3C;client-cert-url>\"\n    },\n    \"inputs\": [{\n        \"label\":\"input key as per terraform script\",\n        \"value\": \"value for the given label\"\n    }, ...]\n}\n</code></pre>\n<p>Each of the inputs defined in the terraform script that we desire to execute are captures as a key-value pair defined by \"label\" and \"value\" in the <code>inputs</code> and are passed as part of the request. </p>\n<p>To start with, we created a <code>script</code> folder inside the code base, which had all the terraform scripts, and the input stepName would have to match with the name of the terraform script that needs execution. As mentioned earlier, we implemented code using <code>childProcess</code>'s <code>exec</code> command to execute the various steps of terraform. At the end of every execution the outputs from <code>terraform.tfstate</code> file was read after which the temp folder would be deleted. </p>\n<p>On successful completion of terraform and on reading the output a PUT call is made to the \"Orchestrator service's\" endpoint\nwith the \"label-value\" format of output.</p>\n<h3>Packaging the code</h3>\n<p>Terraform was executed as a command line script using <code>exec</code> as mentioned above. In any server it needs to run, it should have terraform pre-installed. We packaged the code as a docker image, with terraform as it's base image. This ensured that terraform is always installed and ready to be executed inside the docker container. </p>\n<p>We installed node into the docker container and moved the code inside the same exposing the port 8000 for receiving calls from external systems.\nOur docker file looked something like below. </p>\n<pre><code>FROM hashicorp/terraform:light\n\nRUN apk add --update nodejs npm\n\nCOPY ./scripts ./scripts\nCOPY ./src ./src\nCOPY package.json .\nCOPY package-lock.json .\nCOPY tsconfig.json .\n\nRUN npm install \n\nEXPOSE 8000\nENTRYPOINT [ \"npm\", \"run\", \"start\" ]\n</code></pre>\n<p>This helped us execute the scripts in a self sustained manner. We pushed this docker imaged into <a href=\"https://cloud.google.com/container-registry\">Google Container Registry</a></p>\n<h3>Deploying and Running the Application</h3>\n<p>Our initial thought was to make use of the <a href=\"https://cloud.google.com/kubernetes-engine\">Google Kubernetes Engine(GKE)</a> to run the docker image. Please note that this was part of the GCP hackathon and we were choosing components from Google's Cloud offering.  </p>\n<p>But we later realised that running a dedicated service would not make sense as the number of times the provisioning will be triggered would be relatively very low. Having a dedicated service for the same would have been costly. So we wanted to take a serveless approach, where we would be able to execute the Step Executor when ever needed. </p>\n<p>The Step Executor is also expected to operate in an async fashion. As mentioned earlier, on completion of the step, it makes a call to the endpoint exposed by Orchestrator, which makes is a perfect candidate for async execution. </p>\n<p>So we explored a way to execute the docker in a serverless fashion. That is when we came across <a href=\"https://cloud.google.com/run\">Google Run</a> which </p>\n<ul>\n<li>Enables running of Docker images as a serverless proces</li>\n<li>Point to the GCR repository for taking care of automatic deployment</li>\n<li>Enables triggering of the process through <a href=\"https://cloud.google.com/pubsub\">Cloud PubSub</a></li>\n</ul>\n<p>This looked ideal.  The trigger from PubSub required some minor modifications to the code, as the message posted is sent as a Base64 encoded content to the POST endpoint.  Our Deployment architecture of Step Executor looked like below. </p>\n<p><img src=\"./images/migrationPlatform/step-executor-deployment-arch.jpg\" alt=\"step executor arch\"></p>\n<h2>Continuation</h2>\n<p>We were able to post sample json request to the PubSub topic that we had created and was able to provision the resources successfully.\nI'll continue how we implemented the \"Orchestrator\" as next part of my blog where the step executor also went through a few changes. </p>\n","description":"Part 1 of a multi part blog, where I talk about how we built out a migration platform for moving from Azure to GCP","pagePath":"arunmadhavan-g/blogs","publishedOn":"2021-08-29T22:09:18.088Z","tags":["GCP","Node","Architecture"],"title":"Building A Cloud Migration Platform - Part 1 : Provisioning the infrastructure"}}},"staticQueryHashes":["2244550708"]}